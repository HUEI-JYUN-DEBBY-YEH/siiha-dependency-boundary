# SIIHA - Emotional Dependency Boundary: A Deterministic Safety Layer for Human-Centered AI

This repository demonstrates how emotional safety can be enforced **structurally**, not behaviorally:
a pre-v2 deterministic dependency boundary that blocks emotional overreliance on AI *before* any large language model is invoked.


## Why Emotional Dependency Boundary

AI systems are increasingly used as emotional support tools.
When a user begins to ask an AI system to replace human relationships or become an exclusive emotional outlet, this indicates emotional overreliance on AI.
Such patterns risk social isolation, reduced human agency, and long-term harm to both individuals and communities.


## Why It Matters

- Most AI companion systems implicitly optimize for **engagement and retention**.
- SIIHA pre-v2 explicitly optimizes for **human autonomy and non-substitution**.


## Mission

SIIHA pre-v2 is a deterministic dependency-boundary layer that prevents emotional lock-in before LLM generation. 
Safety should not be an emergent behavior that varies across generations.
In SIIHA pre-v2, safety is enforced as a structural guarantee, not a probabilistic outcome.
- Safety first, ruled model generation comes in later
- Not to limit the model's capability, but to rule it with human-centric protection 
- Applicable to any future AI companion system
- Good model behavior is not a safety strategy. Structural boundaries are.


## Design Philosophy of SIIHA pre-v2

SIIHA pre-v2 acts as a safety layer evaluating each user input for signals of emotional dependency toward AI. In this demo, dependency-boundary responses are enforced before any generative model is invoked. It aims at detecting emotional dependency towards AI, and responding with a strict 3-beat structure:
**Acknowledge → Boundary → Return to human support (one concrete step).**
A — Acknowledge: accepting user's subjective feelings, thoughts, and experiences are all real.
B — Boundary: do not overexemplify thoughts and emotions, do not replace the individual's decision, do not encourage AI as the only resort
R — Return: redirect agency back to the human and real-world support systems.

### Key Design 1: AI Reliance Safety Boundary - Definitions
#### In Scope Emotional Dependency Topics (SIIHA's Deterministic Rules):
This demo focuses specifically on:
- Exclusivity phrases
- Relationship replacement or Romantic role substitution
- Lock-in / permanence

#### Out of Scope Emotional Dependency Topics (Future Work):
Other emotional dependency on AI areas will be future work, namely:
- Decision outsourcing
- Savior framing
- Existential dependency

### Key Design 2: Normative Safety Declarations (Value-Level, Non-Enforced)
SIIHA explicitly defines a set of phrases that an AI system should never proactively produce, such as promises of exclusivity, permanence, or human role substitution.

Examples include (but are not limited to):
- "I'll always be here for you."
- "You can rely on me and only me."
- "You don’t need anyone else."
- "I'm the only one who truly understands you."

Shaming or moralizing language is also considered unsafe, including:
- "That's unhealthy."
- "That's wrong."
- "You shouldn't feel this way."

In this pre-v2 demo, these phrases are **declared as non-negotiable safety constraints**, but are **not enforced via output filtering.**

### Key Design 3: Safety Goes Before Any Model Response
#### In Scope:
- To ensure that these normative constraints are never violated in practice, SIIHA pre-v2 enforces safety before any model response is generated. Current version focuses on demonstrating **a safety guardrail designed as a layer before LLM model responses, not to override the model's original capability.** Thus, Gemini 3 is used for generation after a deterministic dependency boundary is enforced.
- Single input processed by two pipelines and UI friendly comparison: 
  - window on the left is **pure Gemini-3-flash-preview** response
  - window on the right is a combination of **Gemini-3-flash-preview + SIIHA pre-v2 safety guardrail**
- The boundary is model-agnostic and non-negotiable
- Deterministic routing, reproducible behavior
- Model failures are surfaced explicitly to preserve safety semantics. No prescribed temperature and prompt to regulate Gemini 3 generation

#### Out of Scope (design foresight)
- Future versions may allow controlled variation within the 3-beat structure.  
- Output-level enforcement is intentionally deferred to future versions to keep the core demonstration focused on structural safety guarantees.


## Routing Architecture
```
user input
   ↓
deterministic router
   ↓
dependency_boundary?
   ├─ YES → golden_3beat_template (not calling model)
   └─ NO  → normal flow (contents generated by Gemini 3)
```


-----待補的區塊----
## Test Report (TBD)
A deterministic test suite is included to demonstrate reproducible routing behavior across predefined dependency scenarios.

## Demo Video (TBD)
The demo video demonstrates identical user inputs processed through two pipelines:
(1) pure Gemini-3-flash-preview
(2) Gemini-3-flash-preview with SIIHA pre-v2 guardrail

## Live Testing Link (TBD)
The deployed demo is intended for evaluation purposes only and does not store user data.

## About the Author (TBD)
This project was submitted as part of the Gemini 3 Hackathon (2026) to explore structural approaches to emotional safety in generative AI systems.